{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T00:15:16.456103Z",
     "start_time": "2021-06-14T00:15:14.305937Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "import matplotlib.animation as animation\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T00:15:17.224205Z",
     "start_time": "2021-06-14T00:15:17.206349Z"
    }
   },
   "outputs": [],
   "source": [
    "class CartPoleDQN():\n",
    "    def __init__(self, episodes=1000, win_cond=195, gamma=.9, \n",
    "                epsilon=1, min_eps=.01, eps_decay=.995, alpha=.001, batch_size=32):\n",
    "        '''\n",
    "        An implementation of deep-Q learning to solve openai-gym's CartPole-v1\n",
    "        \n",
    "        \n",
    "        episodes: max number of episodes to run\n",
    "        win_cond: the scoring criteria to consider the environment solved\n",
    "        gamma: discount factor on future rewards\n",
    "        epsilon: agent chooses greedy action with probability(1-epsilon)\n",
    "        min_eps: minimum epsilon value\n",
    "        eps_decay: rate of decay for epsilon term (how quickly the agent shifts from exploration to exploitation)\n",
    "        alpha: learning rate for tf.keras.optimizers.Adam\n",
    "        batch_size: how many states to train on during experience replay\n",
    "        '''\n",
    "        self.episodes = episodes\n",
    "        self.win_cond = win_cond\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.min_eps = min_eps\n",
    "        self.eps_decay = eps_decay\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.env = gym.make('CartPole-v1')\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(24, input_dim=4, activation='relu'))\n",
    "        self.model.add(Dense(24, activation='relu'))\n",
    "        self.model.add(Dense(2, activation='linear'))\n",
    "        self.model.compile(loss='mse', optimizer=Adam(learning_rate=self.alpha))\n",
    "        \n",
    "        self.history = []\n",
    "        \n",
    "    def save_memory(self, state, action, reward, new_state, done):\n",
    "        self.memory.append((state, action, reward, new_state, done))\n",
    "        \n",
    "    def choose_action(self, state, epsilon):\n",
    "        if np.random.random() < epsilon:\n",
    "            return self.env.action_space.sample() \n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state))\n",
    "    \n",
    "    \n",
    "    def reshape_state(self, state):\n",
    "        return np.reshape(state, [1,4])\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, new_state, done in batch:\n",
    "            new_q = reward\n",
    "            if not done:\n",
    "                new_q = reward + self.gamma*np.max(self.model.predict(new_state)[0])\n",
    "            q_values = self.model.predict(state)\n",
    "            q_values[0][action] = new_q            \n",
    "            self.model.fit(state, q_values, verbose=0)\n",
    "        \n",
    "        if self.epsilon > self.min_eps:\n",
    "            self.epsilon *= self.eps_decay\n",
    "            \n",
    "            \n",
    "    def run(self):\n",
    "        scores = deque(maxlen=100)\n",
    "        for episode in range(self.episodes):\n",
    "            state = self.reshape_state(self.env.reset())\n",
    "            done = False\n",
    "            i = 0\n",
    "            while not done:\n",
    "#                 self.env.render()\n",
    "                action = self.choose_action(state, self.epsilon)\n",
    "                new_state, reward, done, _ = self.env.step(action)\n",
    "                new_state = self.reshape_state(new_state)\n",
    "                self.save_memory(state, action, reward, new_state, done)\n",
    "                state = new_state\n",
    "                i += 1\n",
    "                \n",
    "            scores.append(i)\n",
    "            self.history.append(i)\n",
    "            mean_score = np.mean(scores)\n",
    "            if episode % 10 == 0:\n",
    "                print(f'Episode {episode}, Score: {i}, Epsilon: {self.epsilon}')\n",
    "            if episode % 100 == 0 and episode >= 100:\n",
    "                print(f'Rolling mean (last 100 trials): {mean_score} after {episode} total trials')\n",
    "                if mean_score >= self.win_cond:\n",
    "                    return episode\n",
    "            self.replay(self.batch_size)\n",
    "        self.env.close()\n",
    "            \n",
    "    def test(self, trials=5):\n",
    "        frames = []\n",
    "        for trial in range(1, trials+1):\n",
    "            state = self.reshape_state(self.env.reset())\n",
    "            done = False\n",
    "            score = 0\n",
    "\n",
    "            while not done:\n",
    "                frames.append(self.env.render(mode='rgb_array'))\n",
    "                action = self.choose_action(state, self.min_eps)\n",
    "                new_state, reward, done, _ = self.env.step(action)\n",
    "                new_state = self.reshape_state(new_state)\n",
    "                self.save_memory(state, action, reward, new_state, done)\n",
    "                state = new_state\n",
    "                score += 1\n",
    "            print(f'Trial: {trial} Score: {score}')\n",
    "        self.env.close()\n",
    "        imageio.mimsave('./videos/solved.gif', frames)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T00:15:21.102448Z",
     "start_time": "2021-06-14T00:15:20.368723Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = CartPoleDQN(episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T00:15:24.994896Z",
     "start_time": "2021-06-14T00:15:24.492448Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.model = keras.models.load_model('./cartpole/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T05:23:15.604124Z",
     "start_time": "2021-06-14T00:15:28.421267Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T05:23:18.313383Z",
     "start_time": "2021-06-14T05:23:18.305419Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(agent.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T23:45:29.963641Z",
     "start_time": "2021-06-12T23:45:29.947768Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T05:23:22.098711Z",
     "start_time": "2021-06-14T05:23:22.074903Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('./data/cartpole.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T20:24:21.952346Z",
     "start_time": "2021-06-13T20:24:21.182559Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.model.save('./cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T05:23:33.348383Z",
     "start_time": "2021-06-14T05:23:28.355419Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T00:42:52.910026Z",
     "start_time": "2021-06-13T00:42:52.907518Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T00:48:29.920743Z",
     "start_time": "2021-06-13T00:48:29.892967Z"
    }
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T05:24:58.126091Z",
     "start_time": "2021-06-14T05:24:58.115675Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T05:24:59.648316Z",
     "start_time": "2021-06-14T05:24:59.391885Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.axhline(195, color='green', linestyle='--', label='Win Criterion')\n",
    "plt.plot(df, alpha=.3, label='Actual Values', color='orange')\n",
    "plt.plot(df.rolling(10).mean(), alpha=.5, label='Rolling Mean (10)', color='blue')\n",
    "plt.plot(df.rolling(100).mean(), label='Rolling Mean (100)', color='green')\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.xlabel('Episodes', fontsize=24)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel('Scores', fontsize=24)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title('Cart Pole DQN', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
